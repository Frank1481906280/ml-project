{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data file\n"
     ]
    }
   ],
   "source": [
    "from tools.data import get_datasets \n",
    "from sklearn import naive_bayes\n",
    "import features\n",
    "import numpy as np\n",
    "\n",
    "# dataset : http://www.mindbigdata.com/opendb/\n",
    "# Mfcc : https://github.com/jameslyons/python_speech_features\n",
    "\n",
    "train, test = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 476.  509.  509. ...,    0.    0.    4.]\n",
      " [ 442.  493.  501. ...,    0.    0.    4.]\n",
      " [ 476.  509.  520. ...,    0.    0.    2.]\n",
      " ..., \n",
      " [ 476.  517.  518. ...,    0.    0.    4.]\n",
      " [ 476.  509.  517. ...,    0.    0.    2.]\n",
      " [ 425.  499.  534. ...,    0.    0.    3.]]\n",
      "[[ 476.  509.  509. ...,    0.    0.    1.]\n",
      " [ 460.  528.  520. ...,    0.    0.   -1.]\n",
      " [ 460.  500.  496. ...,    0.    0.   -1.]\n",
      " ..., \n",
      " [ 476.  517.  518. ...,    0.    0.    1.]\n",
      " [ 476.  509.  517. ...,    0.    0.    1.]\n",
      " [ 425.  499.  534. ...,    0.    0.    1.]]\n"
     ]
    }
   ],
   "source": [
    "#mtrain et mtest -> Ensemble de données avec juste des signaux valides\n",
    "#btrain et btest -> Ensemble donn/es avec classe -1 (pas un signal) et 1 (est un signal)\n",
    "mtrain, mtest = remove_class(train, -1),remove_class(test, -1)\n",
    "btrain, btest = replace_classes(train, [i for i in range(10)],1),replace_classes(test, [i for i in range(10)],1)\n",
    "\n",
    "print(mtrain)\n",
    "print(btrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo :\n",
    "\n",
    "- changer la variable nb_capteur pour nb_signal.\n",
    "- calculer dynamiquement la taille des frames à utiliser et le step, pour pouvoir avoir un nombre fixe de ceptrum pour un signal.\n",
    "- feature mfcc_std\n",
    "- Tester d'autre algorithmes de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mu - ~220Hz - 4 capteurs\n",
    "#MW - ~512Hz -\n",
    "#EP - ~128Hz\n",
    "#IN - ~128Hz\n",
    "#Each sample of the dataset last about 2 secs.\n",
    "\n",
    "def getmfcc2(data, nbcapteurs=4, buffer_size=512, numcep=13, numframes=94):\n",
    "    \"\"\" \n",
    "    Dynamically calculate the window size and window step for each signal to obtain a given number of frame.\n",
    "    \n",
    "    unfinished....\n",
    "    \"\"\"\n",
    "    \n",
    "    mfcc_features = np.zeros((data.shape[0], nbcapteurs, numframe, numcep)) #hardcodé la valeur pour le nombre de frame...\n",
    "    #fbank_feat = np.zeros((data.shape[0], numbank))\n",
    "    print('shape', mfcc_features.shape)\n",
    "    \n",
    "    for x, d in enumerate(data):    \n",
    "        length = int(d[0])\n",
    "        #reversing the computation of the number of frame\n",
    "        frame_len = length / numframes #=winlen*samplerate\n",
    "        #frame_step =  #=winstep*sample rate\n",
    "        print('expected',numframes,'calculated',1+ int(math.ceil((1.0*length - frame_len)/frame_step)))\n",
    "#      numframes = 1 + int(math.ceil((1.0*slen - frame_len)/frame_step))\n",
    "        \n",
    "        for i in range(nbcapteurs):\n",
    "            pass\n",
    "\n",
    "    return mfcc_features\n",
    "\n",
    "\n",
    "def getmfcc(data, nbcapteurs=4, buffer_size=512, numcep=13):\n",
    "    \"\"\" \n",
    "    Consider each signal as a whole (including the zero-padding). \n",
    "    While this technique return a fixed number of for all signal, this causes a severed distorsion in the resonnance because of the zero padding.\n",
    "    \n",
    "    returns a tensor (nb_examples x nb_capteurs x numframes x numcep)\n",
    "    \"\"\"\n",
    "    \n",
    "    mfcc_features = np.zeros((data.shape[0], nbcapteurs, 101, numcep)) #hardcodé la valeur pour le nombre de frame...\n",
    "    #fbank_feat = np.zeros((data.shape[0], numbank))\n",
    "    print('shape', mfcc_features.shape)\n",
    "    \n",
    "    for x, d in enumerate(data):    \n",
    "        length = int(d[0])\n",
    "        \n",
    "        for i in range(nbcapteurs):\n",
    "\n",
    "            #signal = d[1+i*buffer_size:1+i*buffer_size + length]# I do not get a fix number of frame if I do not use the zero-padding.\n",
    "            #print(length)\n",
    "            signal = d[1+i*buffer_size: 1+(i+1)*buffer_size]\n",
    "            mfcc_features[x,i,:,:] = features.mfcc(signal, buffer_size, numcep=numcep)\n",
    "    \n",
    "    return mfcc_features\n",
    "\n",
    "\n",
    "def most_resonnant_by_signal(data,nbcapteurs=4,buffer_size=512, numcep=30):\n",
    "    \"\"\"\n",
    "    Returns a matrix of shape ( nb of examples x nb of signals)\n",
    "    where each element at index i,j is the index of the most resonnant ceptrum by signal.\n",
    "    \"\"\"\n",
    "\n",
    "    feat = np.zeros((data.shape[0], nbcapteurs))\n",
    "    \n",
    "    for x, d in enumerate(data): \n",
    "        length = int(d[0])\n",
    "        \n",
    "        for i in range(nbcapteurs):\n",
    "\n",
    "            signal = d[1+i*buffer_size:1+i*buffer_size + length]# I do not get a fix number of frame if I do not use the zero-padding.\n",
    "            feat[x,i] = np.argmax(features.mfcc(signal, buffer_size, numcep=numcep))\n",
    "    \n",
    "    return feat\n",
    "    \n",
    "\n",
    "def most_resonnance_std(mfcc):\n",
    "    \"\"\"\n",
    "    Take in input a 4d array of which of shape (nb_examples x nb_capteurs x num_frames x num_ceptrum)\n",
    "    this function supports the possibility an different number frame by signal\n",
    "    returns\n",
    "    \n",
    "    \n",
    "    not finished.\n",
    "    \"\"\"\n",
    "              \n",
    "    print(mfcc.shape)\n",
    "    i,c,f,x = mfcc.shape\n",
    "    rez = np.apply_along_axis(np.argmax,3,mfcc)\n",
    "              \n",
    "    print(rez)\n",
    "    return rez\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def results(data, nbcapteurs=4, buffer_size=512, numcep=13, numframes=94):\n",
    "    \"\"\" data : longueur | 512 mesures pour capteur 1 | 512 mesures pour capteur 2 | 512 mesures pour capteur 3 | 512 mesures pour capteur 4 | Chiffre vu | \"\"\"\n",
    "    return data[:,-1]\n",
    "\n",
    "def remove_class(data, target, copy=True):\n",
    "    \"\"\"\n",
    "    Remove all examples which class == target.\n",
    "    assumes that the class is at the last index of the data\n",
    "    \"\"\"\n",
    "    if copy :\n",
    "        return np.array(data[data[:,-1] != -1],copy=True)\n",
    "    else:\n",
    "        return data[data[:,-1] != -1]\n",
    "\n",
    "def replace_classes(data, to_replace, replace_by, copy = True):\n",
    "    \"\"\"\n",
    "    For all examples which class in to_replace. Chance class for replace_by\n",
    "    assumes that the class is at the last index of the data\n",
    "    \"\"\"\n",
    "    if copy:\n",
    "        data = np.array(data,copy=True)\n",
    "    \n",
    "    for x in data:\n",
    "        if x[-1] in to_replace:\n",
    "            x[-1] = replace_by\n",
    "    \n",
    "    return data\n",
    "\n",
    "def quicktest(train,train_result,test,test_result,model):\n",
    "    \"\"\"Train and test model and print relative information\"\"\"\n",
    "    print(\"Training \"+str(train.shape[0])+\" examples...\")\n",
    "    model.fit(train,train_result)\n",
    "    print(\"Testing on \"+str(test.shape[0])+\" examples...\")\n",
    "    y = model.predict(test)\n",
    "    print(\"Errors maded \" +str(np.sum(test_result != y)))\n",
    "    print(\"Predictions : \")\n",
    "    print(y)\n",
    "    print(\"Reality check : \")\n",
    "    print(test_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "La prochaine section teste les données brutes dans un classifieur de Bayes naïf. \n",
    "Étrangement, le procédé donne 100% pour tous les types de classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 30000 examples...\n",
      "Testing on 10983 examples...\n",
      "Errors maded 2930\n",
      "Predictions : \n",
      "[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "Reality check : \n",
      "[-1.  1.  1. ..., -1.  1. -1.]\n",
      "Training 21827 examples...\n",
      "Testing on 8053 examples...\n",
      "Errors maded 7182\n",
      "Predictions : \n",
      "[ 6.  6.  8. ...,  6.  5.  5.]\n",
      "Reality check : \n",
      "[ 7.  7.  0. ...,  4.  1.  0.]\n",
      "Training 30000 examples...\n",
      "Testing on 10983 examples...\n",
      "Errors maded 8053\n",
      "Predictions : \n",
      "[-1. -1. -1. ..., -1. -1. -1.]\n",
      "Reality check : \n",
      "[-1.  7.  7. ..., -1.  0. -1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if False: # if True, it will not train and test on the whole dataset. this is for developping purpose\n",
    "    train_cut = 10 #takes only the 'train_cut' first example in training set.\n",
    "    test_cut = 10000#takes only the 'train_cut' first example in training set.\n",
    "\n",
    "    quicktest(btrain[:train_cut],results(btrain[:train_cut]), btest[:test_cut],results(btest[:test_cut]),naive_bayes.GaussianNB())\n",
    "    quicktest(mtrain[:train_cut],results(mtrain[:train_cut]), mtest[:test_cut],results(mtest[:test_cut]),naive_bayes.GaussianNB())\n",
    "    quicktest(train[:train_cut],results(train[:train_cut]), test[:test_cut],results(test[:test_cut]),naive_bayes.GaussianNB())\n",
    "elif False :\n",
    "    #Classification binaire\n",
    "    quicktest(btrain,results(btrain), btest, results(btest),naive_bayes.GaussianNB())\n",
    "    #Classification multiclasse sans -1\n",
    "    quicktest(mtrain,results(mtrain), mtest, results(mtest),naive_bayes.GaussianNB())\n",
    "    #Classification multiclasse avec -1\n",
    "    quicktest(train, results(train), test, results(test), naive_bayes.GaussianNB())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prochaine section teste le vecteur de feature qu'est le vecteur des indexes du ceptrum le plus résonnant pour chaque capteurs. Le feature vector est donc de taille 4 pour le casque Muse.\n",
    "\n",
    "###Classification binaire\n",
    "Training 30000 examples...\n",
    "Testing on 10983 examples...\n",
    "Errors maded 2930\n",
    "-> 26.678 % d'erreurs\n",
    "\n",
    "###Classification multiclasse sans -1\n",
    "Training 21827 examples...\n",
    "Testing on 8053 examples...\n",
    "Errors maded 7182\n",
    "-> 89.18% d'erreurs\n",
    "\n",
    "###Classification multiclasse avec -1\n",
    "Training 30000 examples...\n",
    "Testing on 10983 examples...\n",
    "Errors maded 8053\n",
    "-> 73.32% d'erreurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_cut = 10 #takes only the 'train_cut' first example in training set.\n",
    "    test_cut = 10000#takes only the 'train_cut' first example in training set.\n",
    "\n",
    "    quicktest(most_resonnant_by_signal(btrain[:train_cut]),results(btrain[:train_cut]), most_resonnant_by_signal(btest[:test_cut]),results(btest[:test_cut]),naive_bayes.GaussianNB())\n",
    "    quicktest(most_resonnant_by_signal(mtrain[:train_cut]),results(mtrain[:train_cut]), most_resonnant_by_signal(mtest[:test_cut]),results(mtest[:test_cut]),naive_bayes.GaussianNB())\n",
    "    quicktest(most_resonnant_by_signal(train[:train_cut]),results(train[:train_cut]), most_resonnant_by_signal(test[:test_cut]),results(test[:test_cut]),naive_bayes.GaussianNB())    \n",
    "\n",
    "else :\n",
    "    #Classification binaire\n",
    "    quicktest(most_resonnant_by_signal(btrain),results(btrain), most_resonnant_by_signal(btest), results(btest),naive_bayes.GaussianNB())\n",
    "    #Classification multiclasse sans -1\n",
    "    quicktest(most_resonnant_by_signal(mtrain),results(mtrain), most_resonnant_by_signal(mtest), results(mtest),naive_bayes.GaussianNB())\n",
    "    #Classification multiclasse avec -1\n",
    "    quicktest(most_resonnant_by_signal(train), results(train), most_resonnant_by_signal(test), results(test), naive_bayes.GaussianNB())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pris d'une démo.\n",
    "class gauss_mv:\n",
    "\n",
    "    def __init__(self,n_dims,cov_type=\"isotropique\"):\n",
    "        self.n_dims = n_dims\n",
    "        self.mu = np.zeros((1,n_dims))\n",
    "        self.cov_type = cov_type\n",
    "        if cov_type==\"isotropique\":\n",
    "            self.sigma_sq = 1.0\n",
    "        elif cov_type==\"diagonale\":\n",
    "            self.sigma_sq = numpy.ones(n_dims)\n",
    "        elif cov_type==\"full\":\n",
    "            self.cov = np.ones((n_dims,n_dims))\n",
    "\n",
    "    # Pour un ensemble d'entrainement, la fonction devrait calculer l'estimateur par MV de la moyenne et de la matrice de covariance\n",
    "    def train(self, train_data):\n",
    "        self.mu = np.mean(train_data, axis=0)\n",
    "        if self.cov_type == \"isotropique\":\n",
    "            self.sigma_sq = np.sum((train_data - self.mu)**2.0) / (self.n_dims * train_data.shape[0])\n",
    "        elif self.cov_type == \"diagonale\":\n",
    "            self.sigma_sq =  numpy.sum((train_data - self.mu) ** 2.0, axis = 0) / train_data.shape[0] \n",
    "        elif self.cov_type == \"full\":\n",
    "            self.cov = np.cov(np.transpose(train_data))\n",
    "        pass\n",
    "    \n",
    "    # Retourne un vecteur de taille nb. ex. de test contenant les log\n",
    "    # probabilités de chaque exemple de test sous le modèle.    \n",
    "    def compute_predictions(self, test_data):\n",
    "\n",
    "        if self.cov_type == \"isotropique\":\n",
    "            # log(constante de normalisation)\n",
    "            c = -self.n_dims * np.log(2*np.pi)/2.0 - self.n_dims*np.log(self.sigma_sq)/2.0\n",
    "            # il faut calculer la valeur de la log-probabilite de chaque exemple\n",
    "            # de test sous le modele determine par mu et sigma_sq. le vecteur\n",
    "            # des probabilites est/sera log_prob\n",
    "            log_prob = c - np.sum((test_data -  self.mu)**2.0,axis=1) / (2.0 * self.sigma_sq)\n",
    "        elif self.cov_type == \"diagonale\":\n",
    "            # on prend le produit du vecteur représentant la diagonale (np.prod(self.sigma)\n",
    "            c = -self.n_dims * np.log(2*np.pi)/2.0 - self.n_dims*np.log(np.prod(self.sigma_sq))/2.0\n",
    "            # on somme sur l'axe 1 après avoir divisé par sigma puisque celui ci aussi est\n",
    "            # de dimension d\n",
    "            log_prob = c - np.sum((test_data -  self.mu)**2.0/ (2.0 * self.sigma_sq),axis=1)\n",
    "        elif self.cov_type == \"full\":\n",
    "            c = -self.n_dims * np.log(2.0*np.pi)/2.0\n",
    "            det = np.linalg.det(self.cov)\n",
    "            c += np.log(det)/2.0\n",
    "            \n",
    "            dmu = test_data-self.mu\n",
    "            inv = np.linalg.inv(self.cov)\n",
    "            \n",
    "            dxs = np.dot(dmu,inv)\n",
    "            dxsx = np.sum(dxs*dmu,axis=1)\n",
    "            log_prob = c - dxsx\n",
    "        return log_prob\n",
    "\n",
    "#Pris de la démo 5.\n",
    "\n",
    "class classif_bayes:\n",
    "\n",
    "    def __init__(self,modeles_mv, priors):\n",
    "        self.modeles_mv = modeles_mv\n",
    "        self.priors = priors\n",
    "        if len(self.modeles_mv) != len(self.priors):\n",
    "            print 'Le nombre de modeles MV doit etre egale au nombre de priors!'\n",
    "        \n",
    "        self.n_classes = len(self.modeles_mv)\n",
    "                                                            \n",
    "    # Retourne une matrice de taille nb. ex. de test x nombre de classes contenant les log\n",
    "    # probabilités de chaque exemple de test sous chaque modèle MV. \n",
    "    def compute_predictions(self, test_data, eval_by_group=False):\n",
    "        log_pred = np.empty((test_data.shape[0],self.n_classes))\n",
    "\n",
    "        for i in range(self.n_classes):\n",
    "            # ici il va falloir utiliser modeles_mv[i] et priors pour remplir\n",
    "            # chaque colonne de log_pred (c'est plus efficace de faire tout une\n",
    "            # colonne a la fois)\n",
    "            \n",
    "            log_pred[:,i] = self.modeles_mv[i].compute_predictions(test_data) +  self.priors[i]\n",
    "\n",
    "        return log_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-71-147e04bbe5ec>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-71-147e04bbe5ec>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    def sort_examples(data)\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#trier les exemples pour classificateur de Bayes\n",
    "def sort_examples(data)\n",
    "    sorted_data = {i:set() for i in [-1] + list(range(10))}\n",
    "\n",
    "    for ex in data:\n",
    "        sorted_data[ex[-1]].append(ex[:-1])\n",
    "    \n",
    "    return sorted_data\n",
    "            \n",
    "#sorting data and training models\n",
    "\n",
    "s = sort_examples(train)\n",
    "models = []\n",
    "for i in list(range(10)) + [-1]  :\n",
    "    model_classe1=gauss_mv(len(train_cols))\n",
    "    model_classe1.train(iris_train1)\n",
    "    \n",
    "#Computing prior. should we assume equiprobability for every result that is not -1\n",
    "priors = []    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
