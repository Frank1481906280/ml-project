{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data file\n"
     ]
    }
   ],
   "source": [
    "from tools.data import get_datasets\n",
    "\n",
    "train, test = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classification -1 vs >=0\n",
    "# on prépare les données:\n",
    "# tout ce qui est un chiffre -> 1\n",
    "# tout ce qui est du bruit -> 0\n",
    "import numpy as np\n",
    "\n",
    "train[train[:,-1] >= 0,-1] =  0\n",
    "test[test[:,-1] >= 0,-1] =  0\n",
    "\n",
    "train[:,-1] = train[:,-1] + 1\n",
    "test[:,-1] = test[:,-1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8173\n",
      "21827\n",
      "(16346, 2050)\n",
      "8173\n",
      "8173\n"
     ]
    }
   ],
   "source": [
    "print (train[:,-1] == 0).sum()\n",
    "print (train[:,-1] == 1).sum()\n",
    "\n",
    "train_0 = np.compress(train[:,-1] == 0, train, axis=0)\n",
    "train_1 = np.compress(train[:,-1] == 1, train, axis=0)[:train_0.shape[0]]\n",
    "\n",
    "train_balanced = np.concatenate((train_0, train_1))\n",
    "\n",
    "print train_balanced.shape\n",
    "\n",
    "indices = np.arange(train_0.shape[0]*2)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_balanced = train_balanced[indices, :]\n",
    "\n",
    "print (train_balanced[:,-1] == 0).sum()\n",
    "print (train_balanced[:,-1] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Merge, Flatten\n",
    "from keras.optimizers import SGD, Adadelta\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "nb_filters = 10\n",
    "filter_length = 5\n",
    "\n",
    "first_layers = []\n",
    "for i in range(4):\n",
    "    first_layers.append(Sequential())\n",
    "    first_layers[-1].add(Convolution1D(nb_filters, filter_length,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(408, 1), init='glorot_normal'))\n",
    "    first_layers[-1].add(MaxPooling1D(pool_length=2))\n",
    "    first_layers[-1].add(Activation('tanh'))\n",
    "    first_layers[-1].add(Convolution1D(nb_filters, filter_length,\n",
    "                        border_mode='valid', init='glorot_normal'))\n",
    "    first_layers[-1].add(MaxPooling1D(pool_length=2))\n",
    "    first_layers[-1].add(Activation('tanh'))\n",
    "    first_layers[-1].add(Flatten())\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge(first_layers, mode='concat', concat_axis=1))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "train_x = train_balanced.astype('float32')\n",
    "valid_x = test[:5000].astype('float32')\n",
    "test_x = test[5000:].astype('float32')\n",
    "\n",
    "train_y = np_utils.to_categorical(train_balanced[:,-1], 2)\n",
    "valid_y = np_utils.to_categorical(test[:5000,-1], 2)\n",
    "test_y = np_utils.to_categorical(test[5000:,-1], 2)\n",
    "\n",
    "train_4 = [train_x[:,1+512*0:1+512*0+408,None], train_x[:,1+512*1:1+512*1+408,None], train_x[:,1+512*2:1+512*2+408,None], train_x[:,1+512*3:1+512*3+408,None]]\n",
    "valid_4 = [valid_x[:,1+512*0:1+512*0+408,None], valid_x[:,1+512*1:1+512*1+408,None], valid_x[:,1+512*2:1+512*2+408,None], valid_x[:,1+512*3:1+512*3+408,None]]\n",
    "test_4 = [test_x[:,1+512*0:1+512*0+408,None], test_x[:,1+512*1:1+512*1+408,None], test_x[:,1+512*2:1+512*2+408,None], test_x[:,1+512*3:1+512*3+408,None]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16346 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "18s - loss: 0.7729 - acc: 0.5225 - val_loss: 0.6238 - val_acc: 0.7480\n",
      "Epoch 2/100\n",
      "18s - loss: 0.6850 - acc: 0.5522 - val_loss: 0.9023 - val_acc: 0.2616\n",
      "Epoch 3/100\n",
      "18s - loss: 0.6903 - acc: 0.5325 - val_loss: 0.6923 - val_acc: 0.2526\n",
      "Epoch 4/100\n",
      "18s - loss: 0.6943 - acc: 0.5231 - val_loss: 0.7582 - val_acc: 0.2616\n",
      "Epoch 5/100\n",
      "18s - loss: 0.6901 - acc: 0.5202 - val_loss: 0.7736 - val_acc: 0.2616\n",
      "Epoch 6/100\n",
      "18s - loss: 0.6880 - acc: 0.5222 - val_loss: 0.6771 - val_acc: 0.7632\n",
      "Epoch 7/100\n",
      "18s - loss: 0.6878 - acc: 0.5270 - val_loss: 0.6896 - val_acc: 0.2608\n",
      "Epoch 8/100\n",
      "18s - loss: 0.6908 - acc: 0.5230 - val_loss: 0.6681 - val_acc: 0.7574\n",
      "Epoch 9/100\n",
      "18s - loss: 0.6878 - acc: 0.5265 - val_loss: 0.6986 - val_acc: 0.2616\n",
      "Epoch 10/100\n",
      "18s - loss: 0.6870 - acc: 0.5261 - val_loss: 0.6262 - val_acc: 0.7476\n",
      "Epoch 11/100\n",
      "18s - loss: 0.6905 - acc: 0.5224 - val_loss: 0.8759 - val_acc: 0.2616\n",
      "Epoch 12/100\n",
      "19s - loss: 0.6889 - acc: 0.5206 - val_loss: 0.6400 - val_acc: 0.7482\n",
      "Epoch 13/100\n",
      "19s - loss: 0.6861 - acc: 0.5374 - val_loss: 0.6787 - val_acc: 0.6640\n",
      "Epoch 14/100\n",
      "19s - loss: 0.6857 - acc: 0.5351 - val_loss: 0.6392 - val_acc: 0.7570\n",
      "Epoch 15/100\n",
      "18s - loss: 0.6837 - acc: 0.5442 - val_loss: 0.6971 - val_acc: 0.3490\n",
      "Epoch 16/100\n",
      "18s - loss: 0.6885 - acc: 0.5333 - val_loss: 0.7297 - val_acc: 0.2616\n",
      "Epoch 17/100\n",
      "19s - loss: 0.6871 - acc: 0.5314 - val_loss: 0.6778 - val_acc: 0.7668\n",
      "Epoch 18/100\n",
      "19s - loss: 0.6848 - acc: 0.5340 - val_loss: 0.5692 - val_acc: 0.7432\n",
      "Epoch 19/100\n",
      "18s - loss: 0.6890 - acc: 0.5276 - val_loss: 0.6742 - val_acc: 0.7690\n",
      "Epoch 20/100\n",
      "18s - loss: 0.6862 - acc: 0.5470 - val_loss: 0.8666 - val_acc: 0.2616\n",
      "Epoch 21/100\n",
      "18s - loss: 0.6864 - acc: 0.5352 - val_loss: 0.9567 - val_acc: 0.2616\n",
      "Epoch 22/100\n",
      "18s - loss: 0.6840 - acc: 0.5346 - val_loss: 0.6706 - val_acc: 0.4178\n",
      "Epoch 23/100\n",
      "18s - loss: 0.6922 - acc: 0.5177 - val_loss: 0.8277 - val_acc: 0.2616\n",
      "Epoch 24/100\n",
      "18s - loss: 0.6857 - acc: 0.5294 - val_loss: 0.6559 - val_acc: 0.7536\n",
      "Epoch 25/100\n",
      "18s - loss: 0.6843 - acc: 0.5505 - val_loss: 0.6372 - val_acc: 0.7696\n",
      "Epoch 26/100\n",
      "19s - loss: 0.6922 - acc: 0.5178 - val_loss: 0.6411 - val_acc: 0.7446\n",
      "Epoch 27/100\n",
      "18s - loss: 0.6890 - acc: 0.5239 - val_loss: 0.5896 - val_acc: 0.7412\n",
      "Epoch 28/100\n",
      "18s - loss: 0.6885 - acc: 0.5273 - val_loss: 0.6599 - val_acc: 0.7484\n",
      "Epoch 29/100\n",
      "18s - loss: 0.6852 - acc: 0.5261 - val_loss: 0.7209 - val_acc: 0.2616\n",
      "Epoch 30/100\n",
      "18s - loss: 0.6886 - acc: 0.5286 - val_loss: 0.6832 - val_acc: 0.7922\n",
      "Epoch 31/100\n",
      "18s - loss: 0.6880 - acc: 0.5283 - val_loss: 0.7477 - val_acc: 0.2616\n",
      "Epoch 32/100\n",
      "19s - loss: 0.6835 - acc: 0.5505 - val_loss: 0.5885 - val_acc: 0.7434\n",
      "Epoch 33/100\n",
      "19s - loss: 0.6850 - acc: 0.5291 - val_loss: 0.6374 - val_acc: 0.7504\n",
      "Epoch 34/100\n",
      "18s - loss: 0.6908 - acc: 0.5301 - val_loss: 0.7169 - val_acc: 0.2616\n",
      "Epoch 35/100\n",
      "18s - loss: 0.6875 - acc: 0.5235 - val_loss: 0.6395 - val_acc: 0.7514\n",
      "Epoch 36/100\n",
      "18s - loss: 0.6896 - acc: 0.5193 - val_loss: 0.7086 - val_acc: 0.2616\n",
      "Epoch 37/100\n",
      "18s - loss: 0.6872 - acc: 0.5335 - val_loss: 0.6900 - val_acc: 0.2594\n",
      "Epoch 38/100\n",
      "18s - loss: 0.6840 - acc: 0.5370 - val_loss: 0.6203 - val_acc: 0.7490\n",
      "Epoch 39/100\n",
      "19s - loss: 0.6925 - acc: 0.5368 - val_loss: 0.7040 - val_acc: 0.2616\n",
      "Epoch 40/100\n",
      "18s - loss: 0.6883 - acc: 0.5223 - val_loss: 0.6931 - val_acc: 0.2610\n",
      "Epoch 41/100\n",
      "18s - loss: 0.6871 - acc: 0.5292 - val_loss: 0.7086 - val_acc: 0.2616\n",
      "Epoch 42/100\n",
      "18s - loss: 0.6895 - acc: 0.5153 - val_loss: 0.6292 - val_acc: 0.7502\n",
      "Epoch 43/100\n",
      "18s - loss: 0.6845 - acc: 0.5437 - val_loss: 0.6572 - val_acc: 0.7480\n",
      "Epoch 44/100\n",
      "18s - loss: 0.6902 - acc: 0.5114 - val_loss: 0.7951 - val_acc: 0.2616\n",
      "Epoch 45/100\n",
      "18s - loss: 0.6891 - acc: 0.5147 - val_loss: 0.6712 - val_acc: 0.7536\n",
      "Epoch 46/100\n",
      "18s - loss: 0.6884 - acc: 0.5223 - val_loss: 0.6768 - val_acc: 0.7538\n",
      "Epoch 47/100\n",
      "18s - loss: 0.6883 - acc: 0.5174 - val_loss: 0.6641 - val_acc: 0.7482\n",
      "Epoch 48/100\n",
      "18s - loss: 0.6949 - acc: 0.5536 - val_loss: 0.6543 - val_acc: 0.7452\n",
      "Epoch 49/100\n",
      "18s - loss: 0.6886 - acc: 0.5215 - val_loss: 0.6933 - val_acc: 0.2616\n",
      "Epoch 50/100\n",
      "18s - loss: 0.6867 - acc: 0.5279 - val_loss: 0.6846 - val_acc: 0.7720\n",
      "Epoch 51/100\n",
      "19s - loss: 0.6871 - acc: 0.5305 - val_loss: 0.7577 - val_acc: 0.2616\n",
      "Epoch 52/100\n",
      "18s - loss: 0.6897 - acc: 0.5165 - val_loss: 0.6954 - val_acc: 0.2616\n",
      "Epoch 53/100\n",
      "18s - loss: 0.6897 - acc: 0.5165 - val_loss: 0.7422 - val_acc: 0.2616\n",
      "Epoch 54/100\n",
      "18s - loss: 0.6886 - acc: 0.5278 - val_loss: 0.7209 - val_acc: 0.2616\n",
      "Epoch 55/100\n",
      "18s - loss: 0.6880 - acc: 0.5185 - val_loss: 0.6794 - val_acc: 0.7564\n",
      "Epoch 56/100\n",
      "18s - loss: 0.6883 - acc: 0.5179 - val_loss: 0.7305 - val_acc: 0.2616\n",
      "Epoch 57/100\n",
      "18s - loss: 0.6874 - acc: 0.5269 - val_loss: 0.7193 - val_acc: 0.2616\n",
      "Epoch 58/100\n",
      "18s - loss: 0.6877 - acc: 0.5220 - val_loss: 0.7682 - val_acc: 0.2616\n",
      "Epoch 59/100\n",
      "18s - loss: 0.6889 - acc: 0.5150 - val_loss: 0.6502 - val_acc: 0.7484\n",
      "Epoch 60/100\n",
      "18s - loss: 0.6879 - acc: 0.5289 - val_loss: 0.6383 - val_acc: 0.7468\n",
      "Epoch 61/100\n",
      "18s - loss: 0.6937 - acc: 0.5237 - val_loss: 0.7261 - val_acc: 0.2616\n",
      "Epoch 62/100\n",
      "18s - loss: 0.6892 - acc: 0.5136 - val_loss: 0.6935 - val_acc: 0.2616\n",
      "Epoch 63/100\n",
      "18s - loss: 0.6858 - acc: 0.5280 - val_loss: 0.6027 - val_acc: 0.7484\n",
      "Epoch 64/100\n",
      "18s - loss: 0.6864 - acc: 0.5277 - val_loss: 0.6519 - val_acc: 0.7520\n",
      "Epoch 65/100\n",
      "18s - loss: 0.6853 - acc: 0.5295 - val_loss: 0.6052 - val_acc: 0.7564\n",
      "Epoch 66/100\n",
      "18s - loss: 0.6883 - acc: 0.5164 - val_loss: 0.7190 - val_acc: 0.2616\n",
      "Epoch 67/100\n",
      "18s - loss: 0.6875 - acc: 0.5194 - val_loss: 0.6429 - val_acc: 0.7450\n",
      "Epoch 68/100\n",
      "18s - loss: 0.6888 - acc: 0.5123 - val_loss: 0.7551 - val_acc: 0.2616\n",
      "Epoch 69/100\n",
      "18s - loss: 0.6886 - acc: 0.5133 - val_loss: 0.6926 - val_acc: 0.2616\n",
      "Epoch 70/100\n",
      "18s - loss: 0.6866 - acc: 0.5243 - val_loss: 0.8142 - val_acc: 0.2616\n",
      "Epoch 71/100\n",
      "18s - loss: 0.6875 - acc: 0.5245 - val_loss: 0.7208 - val_acc: 0.2616\n",
      "Epoch 72/100\n",
      "18s - loss: 0.6876 - acc: 0.5215 - val_loss: 0.7072 - val_acc: 0.2616\n",
      "Epoch 73/100\n",
      "18s - loss: 0.6862 - acc: 0.5207 - val_loss: 0.6898 - val_acc: 0.5488\n",
      "Epoch 74/100\n",
      "18s - loss: 0.6910 - acc: 0.5206 - val_loss: 0.7374 - val_acc: 0.2616\n",
      "Epoch 75/100\n",
      "18s - loss: 0.6863 - acc: 0.5360 - val_loss: 0.7001 - val_acc: 0.2616\n",
      "Epoch 76/100\n",
      "18s - loss: 0.6881 - acc: 0.5138 - val_loss: 0.7273 - val_acc: 0.2616\n",
      "Epoch 77/100\n",
      "18s - loss: 0.6888 - acc: 0.5161 - val_loss: 0.7374 - val_acc: 0.2616\n",
      "Epoch 78/100\n",
      "18s - loss: 0.6883 - acc: 0.5110 - val_loss: 0.6529 - val_acc: 0.7454\n",
      "Epoch 79/100\n",
      "18s - loss: 0.6882 - acc: 0.5174 - val_loss: 0.6966 - val_acc: 0.2616\n",
      "Epoch 80/100\n",
      "18s - loss: 0.6884 - acc: 0.5165 - val_loss: 0.6882 - val_acc: 0.7704\n",
      "Epoch 81/100\n",
      "18s - loss: 0.6881 - acc: 0.5149 - val_loss: 0.7223 - val_acc: 0.2616\n",
      "Epoch 82/100\n",
      "18s - loss: 0.6876 - acc: 0.5137 - val_loss: 0.7180 - val_acc: 0.2616\n",
      "Epoch 83/100\n",
      "19s - loss: 0.6870 - acc: 0.5226 - val_loss: 0.8877 - val_acc: 0.2616\n",
      "Epoch 84/100\n",
      "18s - loss: 0.6851 - acc: 0.5209 - val_loss: 0.5761 - val_acc: 0.7428\n",
      "Epoch 85/100\n",
      "19s - loss: 0.6883 - acc: 0.5174 - val_loss: 0.6643 - val_acc: 0.7524\n",
      "Epoch 86/100\n",
      "18s - loss: 0.6860 - acc: 0.5281 - val_loss: 0.6108 - val_acc: 0.7440\n",
      "Epoch 87/100\n",
      "18s - loss: 0.6857 - acc: 0.5256 - val_loss: 0.7654 - val_acc: 0.2616\n",
      "Epoch 88/100\n",
      "18s - loss: 0.6867 - acc: 0.5262 - val_loss: 0.7111 - val_acc: 0.2616\n",
      "Epoch 89/100\n",
      "19s - loss: 0.6869 - acc: 0.5225 - val_loss: 0.6785 - val_acc: 0.7768\n",
      "Epoch 90/100\n",
      "18s - loss: 0.6814 - acc: 0.5494 - val_loss: 0.8307 - val_acc: 0.2616\n",
      "Epoch 91/100\n",
      "18s - loss: 0.6906 - acc: 0.5231 - val_loss: 0.6915 - val_acc: 0.2616\n",
      "Epoch 92/100\n",
      "18s - loss: 0.6896 - acc: 0.5200 - val_loss: 0.6470 - val_acc: 0.7450\n",
      "Epoch 93/100\n",
      "18s - loss: 0.6873 - acc: 0.5217 - val_loss: 0.6948 - val_acc: 0.2616\n",
      "Epoch 94/100\n",
      "18s - loss: 0.6872 - acc: 0.5304 - val_loss: 0.6232 - val_acc: 0.7508\n",
      "Epoch 95/100\n",
      "18s - loss: 0.6860 - acc: 0.5266 - val_loss: 0.7076 - val_acc: 0.2616\n",
      "Epoch 96/100\n",
      "18s - loss: 0.6861 - acc: 0.5239 - val_loss: 0.6200 - val_acc: 0.7460\n",
      "Epoch 97/100\n",
      "18s - loss: 0.6861 - acc: 0.5257 - val_loss: 0.6785 - val_acc: 0.7598\n",
      "Epoch 98/100\n",
      "18s - loss: 0.6862 - acc: 0.5171 - val_loss: 0.6755 - val_acc: 0.7578\n",
      "Epoch 99/100\n",
      "18s - loss: 0.6856 - acc: 0.5313 - val_loss: 0.6434 - val_acc: 0.7492\n",
      "Epoch 100/100\n",
      "18s - loss: 0.6865 - acc: 0.5162 - val_loss: 0.7041 - val_acc: 0.2616\n",
      "[0.70401845779503425, 0.27110145412000669]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "nb_epoch = 100\n",
    "\n",
    "model.fit(train_4, train_y,\n",
    "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          show_accuracy=True, verbose=2,\n",
    "          validation_data=(valid_4, valid_y))\n",
    "score = model.evaluate(test_4, test_y,\n",
    "                       show_accuracy=True, verbose=0)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61743914956494994, 0.73006852749456796]\n",
      "Train on 30000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "32s - loss: 0.6286 - acc: 0.7186 - val_loss: 0.6145 - val_acc: 0.7396\n",
      "Epoch 2/100\n",
      "32s - loss: 0.6015 - acc: 0.7253 - val_loss: 0.5728 - val_acc: 0.7408\n",
      "Epoch 3/100\n",
      "32s - loss: 0.6172 - acc: 0.7217 - val_loss: 0.5834 - val_acc: 0.7404\n",
      "Epoch 4/100\n",
      "32s - loss: 0.6166 - acc: 0.7224 - val_loss: 0.5868 - val_acc: 0.7408\n",
      "Epoch 5/100\n",
      "32s - loss: 0.6079 - acc: 0.7302 - val_loss: 0.5746 - val_acc: 0.7408\n",
      "Epoch 6/100\n",
      "32s - loss: 0.5953 - acc: 0.7304 - val_loss: 0.5898 - val_acc: 0.7408\n",
      "Epoch 7/100\n",
      "32s - loss: 0.6254 - acc: 0.7178 - val_loss: 1.5663 - val_acc: 0.7384\n",
      "Epoch 8/100\n",
      "32s - loss: 1.2727 - acc: 0.5930 - val_loss: 0.8187 - val_acc: 0.7386\n",
      "Epoch 9/100\n",
      "32s - loss: 1.3237 - acc: 0.5839 - val_loss: 0.5947 - val_acc: 0.7392\n",
      "Epoch 10/100\n",
      "33s - loss: 1.2637 - acc: 0.6048 - val_loss: 2.3780 - val_acc: 0.7384\n",
      "Epoch 11/100\n",
      "32s - loss: 1.3935 - acc: 0.5946 - val_loss: 0.8742 - val_acc: 0.2614\n",
      "Epoch 12/100\n",
      "33s - loss: 1.3669 - acc: 0.6047 - val_loss: 0.7071 - val_acc: 0.7396\n",
      "Epoch 13/100\n",
      "33s - loss: 1.3031 - acc: 0.5934 - val_loss: 1.7765 - val_acc: 0.7386\n",
      "Epoch 14/100\n",
      "32s - loss: 1.3655 - acc: 0.5956 - val_loss: 1.2559 - val_acc: 0.7384\n",
      "Epoch 15/100\n",
      "32s - loss: 1.3902 - acc: 0.5911 - val_loss: 1.2016 - val_acc: 0.7384\n",
      "Epoch 16/100\n",
      "32s - loss: 1.3115 - acc: 0.5951 - val_loss: 0.7431 - val_acc: 0.7384\n",
      "Epoch 17/100\n",
      "32s - loss: 1.2886 - acc: 0.5983 - val_loss: 0.6093 - val_acc: 0.7388\n",
      "Epoch 18/100\n",
      "32s - loss: 1.2959 - acc: 0.5923 - val_loss: 1.9864 - val_acc: 0.7384\n",
      "Epoch 19/100\n",
      "32s - loss: 1.3643 - acc: 0.5823 - val_loss: 1.0175 - val_acc: 0.7384\n",
      "Epoch 20/100\n",
      "32s - loss: 1.2833 - acc: 0.5911 - val_loss: 2.6204 - val_acc: 0.7384\n",
      "Epoch 21/100\n",
      "32s - loss: 1.3404 - acc: 0.6000 - val_loss: 0.9161 - val_acc: 0.2614\n",
      "Epoch 22/100\n",
      "32s - loss: 1.2940 - acc: 0.5951 - val_loss: 0.6842 - val_acc: 0.7398\n",
      "Epoch 23/100\n",
      "32s - loss: 1.3256 - acc: 0.5883 - val_loss: 0.7149 - val_acc: 0.2606\n",
      "Epoch 24/100\n",
      "32s - loss: 1.3081 - acc: 0.5935 - val_loss: 0.8091 - val_acc: 0.2614\n",
      "Epoch 25/100\n",
      "32s - loss: 1.3541 - acc: 0.5926 - val_loss: 1.9303 - val_acc: 0.7384\n",
      "Epoch 26/100\n",
      "32s - loss: 1.3705 - acc: 0.5935 - val_loss: 1.2329 - val_acc: 0.7384\n",
      "Epoch 27/100\n",
      "32s - loss: 1.2899 - acc: 0.5994 - val_loss: 0.5745 - val_acc: 0.7392\n",
      "Epoch 28/100\n",
      "32s - loss: 1.4172 - acc: 0.5846 - val_loss: 1.2498 - val_acc: 0.7384\n",
      "Epoch 29/100\n",
      "32s - loss: 1.2570 - acc: 0.5992 - val_loss: 1.6466 - val_acc: 0.7384\n",
      "Epoch 30/100\n",
      "33s - loss: 1.4059 - acc: 0.5843 - val_loss: 0.7007 - val_acc: 0.2604\n",
      "Epoch 31/100\n",
      "33s - loss: 1.2350 - acc: 0.5967 - val_loss: 0.5748 - val_acc: 0.7394\n",
      "Epoch 32/100\n",
      "32s - loss: 1.3975 - acc: 0.5833 - val_loss: 0.7335 - val_acc: 0.2614\n",
      "Epoch 33/100\n",
      "32s - loss: 1.4075 - acc: 0.5847 - val_loss: 0.9772 - val_acc: 0.7386\n",
      "Epoch 34/100\n",
      "32s - loss: 1.3619 - acc: 0.5906 - val_loss: 2.3550 - val_acc: 0.7384\n",
      "Epoch 35/100\n",
      "32s - loss: 1.3520 - acc: 0.5985 - val_loss: 0.6514 - val_acc: 0.7386\n",
      "Epoch 36/100\n",
      "32s - loss: 1.3279 - acc: 0.5900 - val_loss: 0.5764 - val_acc: 0.7390\n",
      "Epoch 37/100\n",
      "32s - loss: 1.3453 - acc: 0.5911 - val_loss: 1.6270 - val_acc: 0.7384\n",
      "Epoch 38/100\n",
      "32s - loss: 1.3003 - acc: 0.5998 - val_loss: 0.7311 - val_acc: 0.2610\n",
      "Epoch 39/100\n",
      "32s - loss: 1.2874 - acc: 0.5903 - val_loss: 1.4158 - val_acc: 0.7384\n",
      "Epoch 40/100\n",
      "32s - loss: 1.4352 - acc: 0.5939 - val_loss: 0.9067 - val_acc: 0.7386\n",
      "Epoch 41/100\n",
      "32s - loss: 1.3318 - acc: 0.6070 - val_loss: 0.5976 - val_acc: 0.7386\n",
      "Epoch 42/100\n",
      "32s - loss: 1.3734 - acc: 0.5903 - val_loss: 1.6564 - val_acc: 0.7384\n",
      "Epoch 43/100\n",
      "32s - loss: 1.4000 - acc: 0.5787 - val_loss: 1.9542 - val_acc: 0.7384\n",
      "Epoch 44/100\n",
      "32s - loss: 1.3814 - acc: 0.5910 - val_loss: 0.8393 - val_acc: 0.7386\n",
      "Epoch 45/100\n",
      "32s - loss: 1.3678 - acc: 0.5891 - val_loss: 0.6174 - val_acc: 0.7386\n",
      "Epoch 46/100\n",
      "32s - loss: 1.2989 - acc: 0.5935 - val_loss: 0.6108 - val_acc: 0.7386\n",
      "Epoch 47/100\n",
      "32s - loss: 1.3498 - acc: 0.5976 - val_loss: 0.8127 - val_acc: 0.2614\n",
      "Epoch 48/100\n",
      "32s - loss: 1.4214 - acc: 0.5944 - val_loss: 2.6272 - val_acc: 0.7384\n",
      "Epoch 49/100\n",
      "32s - loss: 1.3679 - acc: 0.5971 - val_loss: 1.2550 - val_acc: 0.2616\n",
      "Epoch 50/100\n",
      "32s - loss: 1.4359 - acc: 0.5761 - val_loss: 0.7446 - val_acc: 0.2614\n",
      "Epoch 51/100\n",
      "32s - loss: 1.3364 - acc: 0.5867 - val_loss: 0.6309 - val_acc: 0.7388\n",
      "Epoch 52/100\n",
      "32s - loss: 1.3319 - acc: 0.5788 - val_loss: 0.9437 - val_acc: 0.7386\n",
      "Epoch 53/100\n",
      "32s - loss: 1.4621 - acc: 0.5923 - val_loss: 0.9500 - val_acc: 0.2614\n",
      "Epoch 54/100\n",
      "32s - loss: 1.5198 - acc: 0.5820 - val_loss: 1.5338 - val_acc: 0.7384\n",
      "Epoch 55/100\n",
      "32s - loss: 1.3842 - acc: 0.5944 - val_loss: 2.8257 - val_acc: 0.7384\n",
      "Epoch 56/100\n",
      "32s - loss: 1.2873 - acc: 0.5858 - val_loss: 2.6562 - val_acc: 0.7384\n",
      "Epoch 57/100\n",
      "32s - loss: 1.4105 - acc: 0.5891 - val_loss: 1.1318 - val_acc: 0.7386\n",
      "Epoch 58/100\n",
      "32s - loss: 1.3514 - acc: 0.5908 - val_loss: 0.7642 - val_acc: 0.2614\n",
      "Epoch 59/100\n",
      "32s - loss: 1.3473 - acc: 0.5918 - val_loss: 1.0507 - val_acc: 0.2614\n",
      "Epoch 60/100\n",
      "32s - loss: 1.3165 - acc: 0.5892 - val_loss: 0.6193 - val_acc: 0.7388\n",
      "Epoch 61/100\n",
      "32s - loss: 1.3064 - acc: 0.5940 - val_loss: 1.1076 - val_acc: 0.7386\n",
      "Epoch 62/100\n",
      "32s - loss: 1.4466 - acc: 0.5892 - val_loss: 0.7049 - val_acc: 0.2610\n",
      "Epoch 63/100\n",
      "32s - loss: 1.3424 - acc: 0.5833 - val_loss: 0.5746 - val_acc: 0.7388\n",
      "Epoch 64/100\n",
      "32s - loss: 1.3130 - acc: 0.5918 - val_loss: 0.5963 - val_acc: 0.7386\n",
      "Epoch 65/100\n",
      "32s - loss: 1.3838 - acc: 0.5916 - val_loss: 1.1069 - val_acc: 0.7386\n",
      "Epoch 66/100\n",
      "32s - loss: 1.3360 - acc: 0.6017 - val_loss: 1.1189 - val_acc: 0.2614\n",
      "Epoch 67/100\n",
      "32s - loss: 1.4030 - acc: 0.5830 - val_loss: 0.5849 - val_acc: 0.7388\n",
      "Epoch 68/100\n",
      "32s - loss: 1.3455 - acc: 0.5853 - val_loss: 1.0587 - val_acc: 0.2614\n",
      "Epoch 69/100\n",
      "32s - loss: 1.3604 - acc: 0.5810 - val_loss: 0.6072 - val_acc: 0.7390\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-e1af1fd7e202>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mshow_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m           validation_data=(valid_4, valid_y))\n\u001b[0m\u001b[0;32m      6\u001b[0m score = model.evaluate(test_4, test_y,\n\u001b[0;32m      7\u001b[0m                        show_accuracy=True, verbose=0)\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, show_accuracy, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m    487\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m                          \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                          shuffle=shuffle, metrics=metrics)\n\u001b[0m\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, metrics)\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    758\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoContext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print score\n",
    "model.fit(train_4, train_y,\n",
    "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          show_accuracy=True, verbose=2,\n",
    "          validation_data=(valid_4, valid_y))\n",
    "score = model.evaluate(test_4, test_y,\n",
    "                       show_accuracy=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ca c'est le résultat qu'on obtient en prenant un classifieur\n",
    "# qui prédit tout le temps 1 (classe majoritaire)\n",
    "print float(np.sum(test[:,-1]==1))/test.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
